---
layout: post
title:  Linking COVID Death Rate to Demographic Patterns
author: <a href="http://chandlerzuo.github.io/">Chandler</a>
---

Talking about mortality in this world-wide pandemic is nothing easy, but there is some questions to ask. In an ideal world where people have equal access to medical resources, deaths out of COVID infection would be pure in the control of the God's dice, and we would see equal death rate across regions. Noticeably, there is difference death rate and the number of infected people or mortality. The number of infections can be influenced by factors outside the medical system, for example how government enforces regulations to control the spread of the virus. Mortality is the multiplication of the number infections and the death rate, thus under the influence of the same factors. Death rate, on the other hand, relies mostly on access to medical resources -- after one gets infected, how easily can they get the right treatment?

Death rates across US so far differ wildly across different regions. [Real-time COVID monitoring built by 1point3acres](https://coronavirus.1point3acres.com/en) provides county level stats. These numbers can be linked with the demographic information from Census Bureau to enable some analysis. Some demographic features presumably can be correlated with death rates. An example is the proportion of old people. Politicians tell us that COVID is more fatal to old people than young people. The following figure compares the county-level death rate with the proportion of population greater than 60. It seems the positive correlation is true when the proportion stays below 35%, but becomes less pronounced when the proportion exceeds that.

![](https://www.dropbox.com/s/0mey4sze3h6ie6r/prop_ge60.jpg?dl=0)

Another example is the proportion of population with health insurance. There are two possible patterns. If infected people need to rely on their own health insurance for treatment, we expect to see negative correlation between health insurance coverage and death rate. Alternatively, if government subsidies health system strongly enough, infected people can be treated regardless of their health insurance coverage status, which means such correlation would not exist. Our data seem to support the former.

![](https://www.dropbox.com/s/ex0tsy7pvggblkx/insurance.jpg?dl=0)

A more disturbing example is the median household example. We hope to see no correlation between income levels and COVID death rates, assuming that in an ideal world medical resources are deployed to all regions regardless of their economic status. Data, however, shows negative correlation between the two, and the pattern even seems to be stronger than the correlation with proportion of aged population. Compare counties with median household income below 50K with those above 100K. Death rates are mostly above 3% for the former counties and below 3% for the latter. 

![](https://www.dropbox.com/s/wz8ljyj5csoeesi/med_house_income.jpg?dl=0)

Features can have confounding effects. The proportion of aged population can be correlated with median household income. Once controlling other factors, what is the effect of median household income? To answer such questions I run a Generalized Linear Model with binomial distribution including the above three variables. Backward selection is used to exclude insignificant variables. Proportion of population older than 60 is the only variable that is excluded. The model results are shown in the following table. To interpret, every 1% increase in health insurace coverage is associated with 4.44% decrease in the log odds of COVID death rate, and every $10K increase in median household income is associated with 3.35% decrease in the log odds of COVID death rate.

| Variable | Coefficient Estimate | P-value |
| Intercept |     -2.700e+00  |  < 2e-16 *** |
| Median Household Income |    -3.350e-06  | 0.000164 *** |
| Proportion of Population with Health Insurance | -4.444e+00  |  2.5e-06 ***|

Correlation is not causation. Factors outside this model may play a role in reality; for example, maybe counties with higher income also have better educated population, and thus are more aware to take early actions when symptoms develop. To improve this model along this direction, I include more demographic features. The next model I build includes the following features:

1. Median household income;
1. Proportion of population with health insurance;
1. Proportion of college educated population;
1. Proportion of female population;
1. Proportino of population older than 60;
1. Proportion of families in different races. There are 7 races from census data: Non-hispanic White, Hispanic and Latino, Black and African American, Asian, Native Americans and Alaska Natives, Native Hawaiin and Other Pacific Islander, Some other race, Two or more races. The model includes the last 6 races to avoid multi-collinearity.

The model results and the interpretation are in the following table:

| Variable | Coefficient Estimate | P-value |
| Intercept | -3.8715  |  < 2e-16 *** |
| Proportion of Population Older than 60 | 2.0019 |  2.34e-05 ***|
| Proportion of Population with College Degree | -1.1698  | 3.37e-08 ***|
| Proportion of Families with Two or More Races | -3.4262   | 0.0533 .  |
| Proportion of Black or African American Families | 0.6147 | 6.11e-08 ***|
| Proportion of Asian Families | 2.6453 | 3.85e-13 ***|
| Proportion of Families with Some Other Races | -1.5529  | 6.83e-05 ***|
| Proportion of Haiwaiian or Other Pacific Islander Families | -11.2095  |  0.0966 .|  

The results are drastically different from the first model. After introducing additional demographic variables, both median household income and health insurance coverage are no longer significant. Rather, the most significant factor is the proportion of Asian Families. Controlling all other factors in this model, with every 1% increase in the proportion of Asian families, there is 2.64% increase in the death rate. The effect is even larger than the proportion of aged population. Another race that is fared less fortunate than other races is the Black and African Americans. Every 1% increase is associated with 0.61% increase in COVID death rate.

How does this model fit? The following figure shows the log ratio of actual death rate v.s. the predicted death rate.

![](https://www.dropbox.com/s/83zgjitvp8hbcu2/normalized_death_rate.jpg?dl=0)

My model apparently has many caveats, which include but are not restricted to:

1. Mortality happens at some delay of infections. Counties where COVID recently begin to spread may have lower death rate because mortality among the newly infected people occurs at some time later. Ideally we need to calculate death rates from cohort data.
1. Counties with limited testing may also show high death rate because the number of reported infections underestimates the true number of infections.
1. The model may indicate regional inequality of medical resource allocation, but it gives no direct proof. If we can obtain medical resource allocation data, we may be able to associate that with the census demographic information to answer that question properly.

For counties with at least 1K infections, this figure shows how the predicted death rate differs from the actual death rate. Food for thought:

1. For counties where my model underpredicts, are they running short of medical supplies? Do they need more news coverage?
1. For counties where my model overpredicts, do they have effective experience to treat the virus that can be shared with other counties?

![](https://www.dropbox.com/s/g3xix9gnzw2it7c/actual_vs_predicted.jpg?dl=0)


**TECHNICAL DETAILS**

CENSUS DATA

I use 2018 American Community Survey 5-year Estimate data for county-level demographics in the US. Information on how to download data can be found on [Census Bureau's developer website](https://www.census.gov/developers/).

COVID DATA

I manually copied data from [1point3acres Live-time Report](https://coronavirus.1point3acres.com/en) snapshot at 4/4/2020 at 2pm EDT.

DATA ANALYSIS

The final model includes 2238 US counties where I can match COVID data with the ACS survey data.

6 counties are excluded from model fitting because they have high leverage according to Cook's distance. These counties are shown in the table below. Acknowledgably, they are the most infected counties by COVID in the US, but they also show quite distinct pattern compared to other US counties. The model excludes them in order to fit the pattern for general US counties.

| State | County | Infected | Death |
| Florida | Miami-Dade | 3667 | 30 |
| New York | Nassau | 13346 | 95 |
| New York | New York | 63306 | 1905 |
| New York | Suffolk | 11370 | 96 |
| New York | Westchester | 13081 | 67 |
| Washington | King | 2787 | 188 |

All codes can be found [here](https://github.com/chandlerzuo/chandlerzuo.github.io/tree/master/codes/covid19).

**ADVERSARIAL EXAMPLES**

Neural network models can be susceptible to adversarial examples, which are perturbed input data too small to be detected by human yet tricky enough to confuse a trained model into making errors. The following is a famous example from [Goodfellow et al. 2014][2]. While the left photo is categorized correctly in the panda category, with some specifically constructed noises, the right photo is incorrectly categorized as in the gibbon category. In fact, such noises can be constructed to confuse the network in an arbitrary way. [Daniel Geng and Rishi Veerapaneni's blog](https://ml.berkeley.edu/blog/2018/01/10/adversarial-examples/) illustrates how to do so using image classification as an example.

![](https://ml.berkeley.edu/blog/assets/2017-10-31-adversarial-examples/goodfellow.png) 

The key step of constructing adversarial examples is to find the **direction** of the input noise that the network is sensitive to. A neural network input often comes in high dimensions. For an RGB image with 128x128px, the dimension is 128x128x3=49152. With such high dimensions, it is unrealistic to assume a neural network model to be robust against noises in all dimensions. To find the most malicious direction of the input noise is essentially to find the dimensions in the input data which a neural network is most sensitive to. Mathematically, such malicious directions can be found by calculating the derivative of the objective function the trained model minimizes against the input data. The derivative calculation is the right tool to find malicious directions because by definition, it is used to find how a function's input can be minimally perturbed to bring the maximally change in its output.

**FAST GRADIENT SIGN METHOD AND LASSO**

We know that neural network models are sensitive to adversarial examples. How can we make neural network to be robust against adversarial noises? Since we already know how to generate such adversarial noises, we can simply augment the training data using these adversarial examples. This idea was proposed by [Goodfellow et al. 2014][2]. Specifically, they proposed the **Fast Gradient Sign Method (FGSM)**. This method generates noises that has the same scale in every dimension, but the sign in each dimension is determined by the gradient calculation. The mathematical formula for an adversarial example is:

<img src="https://dl.dropboxusercontent.com/s/jsmuuooq3803wia/eqn1.png" height="20"/>

In a 1-layer neural network model with sigmoid activation, [Goodfellow et al. 2014][2] reckons that such learning is closely related to LASSO penalty. This is because the objective function with FGSM examples is:

<img src="https://dl.dropboxusercontent.com/s/1ymuf6bf86mbvjp/eqn2.png" height="80"/>

Comparing this to the objective function of [LASSO-penalized likehood estimation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3873110/):

<img src="https://dl.dropboxusercontent.com/s/y0u6khbx10x27f3/eqn3.png" height="40"/>

FGSM simply changes the order between sigmoid activation and imposing the LASSO penalty. Because of this, [Goodfellow et al. 2014][2] states that FGSM has regularization effect similar to LASSO. The difference between these two types of regularization is that the penalty in FGSM automatically deactivates if the prediction is confident enough, while LASSO penalty focuses more on the worst case scenarios.

**GENERALIZED FGSM**

The relationship between FGSM and LASSO motivates me to study the asymptotic behavior of FGSM in simple regression models. In fact, despite much numerical results showing the benefit of using FGSM for real data, there is not much theoretical justification. For LASSO, decades of theoretical research have yielded  much understanding on its benefits, which have well explained its role in neural network regularization (commonly known as L1 weight decay). If we can derive statistical properties for FGSM in simple regression models, such as linear regression and logistic regression, the insights may help us interpret its effectiveness in deep neural network models.

[My recent paper][1] is an effort in this direction. The theoretical framework is built for Generalized FGSM estimation for [generalized linear models (GLM)](https://en.wikipedia.org/wiki/Generalized_linear_model). The theory is built for estimation with the following objective function:

<img src="https://dl.dropboxusercontent.com/s/1i3zxapk140vxdb/eqn4.png" height="80"/>

This setting is more general than FGSM with sigmoid activation in that

1. the activation function can not only be the sigmoid function;
2. the penalty function can not only be LASSO.

The first point is actually a limit; the framework includes linear regression and logistic regression, but exclude activation functions such as ReLU that does not correspond to GLMs. The second point is, however, more interesting. Before, we have seen that if the penalty function is LASSO, the objective function corresponds to learning using FGSM adversarial examples. If we choose another penalty function, such as general Lr shrinkage or [SCAD] penalty, the corresponding schema to generate adversarial noises is:

<img src="https://dl.dropboxusercontent.com/s/68xv54cwgglsoi0/eqn5.png" height="40"/>

This gives a large number of ways to generate adversarial examples, which can be interesting to evaluate empirically.

**ASYMPTOTICS FOR FGSM-TYPE LEARNING**

It is already know that penalized likelihood estimation for GLM has three properties:

- *Root-n consistency*. In layman's term, the standard error for the parameter estimator is halved every time the training sample is quadrupled. This is a desirable statistical property for regression models, and is the best rate achievable because of [Cramer-Rao's Bound](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound).
- *Sparsity*. The parameter estimator is sparse. This creates some bias but may reduce the overall estimation error due to [bias-variance tradeoff](http://www.cs.cmu.edu/~wcohen/10-601/bias-variance.pdf).
- *Oracle property* for non-concave penalties. If the true parameter is sparse, the estimated parameter is almost as accurate as if we knew which parameters were zero. This only happens if the penalty function is non-concave, such as SCAD or Lr with 0<r<1.

The main result of [My paper][1] is that all these properties are inherited by Generalized FGSM. Moreover, the asymptotic distribution is highly similar to penalized likelihood estimation. For both methods, the asymptotic distribution follows the form

<img src="https://dl.dropboxusercontent.com/s/ywfhaioalvylv4a/eqn6.png" height="20"/>

For Generalized FGSM, the asymptotically maximized function with Lr penalty is:

<img src="https://dl.dropboxusercontent.com/s/2d5kbbvt200ea8s/eqn7.png" height="60"/>

For penalized likelihood estimation, the corresponding asymptotically maximized function is:

<img src="https://dl.dropboxusercontent.com/s/f02bo32t8e1jmtw/eqn8.png" height="60"/>

**COMPARING GENERALIZED FGSM WITH PENALIZED LIKELIHOOD**

The asymptotic results have two implications.

*Automatically Scaled Penalty*

The multipler of the penalty in Generalized FGSM is automatically scaled by the dispersion of error. This is desirable since the tuning parameter, lambda, can be uncoupled from noise level in the data, and thus be selected based on the sparsity level alone. For penalized likelihood estimation, on the other hand, the selected lambda need be scaled against a heuristically estimated noise level.

*Sign Neutrality*

Generalized FGSM is different from penalized likelihood estimation if the training data is not *sign neutral*. This concept is related to the quantity V in the asymptotic equations:

<img src="https://dl.dropboxusercontent.com/s/o6wbuej87sepby1/eqn9.png" height="20"/>

When V is non-zero, it introduces additional bias compared to penalized likelihood estimation. For linear regression models, V=0 requires trivial conditions that can be assumed true in most practical cases. However, for logistic regression, V=0 requires that the data sampling need be balanced in a certain way.

Sign neutrality requires that the average sign of errors across all training data is roughly 0. To see how balanced the sampling should be in a logistic regression model, consider a single binary random variable Y with probability p for Y=1 and 1-p for Y=0. The expected sign of the error Y-p is 1*p+(-1)*(1-p)=2p-1. This is equal to 0 only when p=0.5. Intuitively, if the training data sampling is sign neutral, the average binary probability across all observations should be roughly 0.5. This condition is not satisfied for any data that are not balanced between the two categories.

One thing to mention here is that, such additional bias does not necessarily make Generalized FGSM inferior to penalized likelihood. Just as LASSO penalty, biases in estimation can trade off with variance to improve overall estimation accuracy. Whether the additional bias in Generalized FGSM improves such tradeoff requires future analysis.

**CONCLUSIONS**

Asymptotics is an important topic in theoretical statistics. Yet, I have often heard critism for such research in that such theory yields little practical usage. As an applied researcher myself, however, I do feel such critism is unfair. Methodological research sometimes move much faster than mathematical theory. But it is not wise to undermine the value of such theory. At least, such theory help answer three questions: *why certain methodology works, how it can be generalized, and where its boundary is*.

There is no doubt that FGSM and the general adversarial examples learning is highly successful. With so much empirical success, I have been curious of the its underlying mathematical mechanism. Such curiosity motivates me to develop the theory in [this paper][1]. Of course, my theory is far from comprehensive, but it does shed light on to the three questions mentioned above. Root-n consistency, sparsity, and oracle properties are all nice properties that explains its success; its generalization can be induced by a large number of penalty functions already used in penalized likelihood; one of its boundaries may be sign neutrality. The theory so far is entirely based on 1-layer neural network models, but I hypothesize such properties have strong implications for deep neural network models as well.

[1]: https://arxiv.org/abs/1810.11711
[2]: https://arxiv.org/abs/1412.6572
[eqn1]: https://dl.dropboxusercontent.com/s/jsmuuooq3803wia/eqn1.png{: height="10"}
[eqn2]: https://dl.dropboxusercontent.com/s/1ymuf6bf86mbvjp/eqn2.png{: height=20}
[eqn3]: https://dl.dropboxusercontent.com/s/y0u6khbx10x27f3/eqn3.png{: height=10}
[eqn4]: https://dl.dropboxusercontent.com/s/1i3zxapk140vxdb/eqn4.png{: height=20}
[eqn5]: https://dl.dropboxusercontent.com/s/68xv54cwgglsoi0/eqn5.png{: height=10}
[eqn6]: https://dl.dropboxusercontent.com/s/ywfhaioalvylv4a/eqn6.png{: height=10}
[eqn7]: https://dl.dropboxusercontent.com/s/2d5kbbvt200ea8s/eqn7.png{: height=30}
[eqn8]: https://dl.dropboxusercontent.com/s/f02bo32t8e1jmtw/eqn8.png{: height=30}
[eqn9]: https://dl.dropboxusercontent.com/s/o6wbuej87sepby1/eqn9.png{: height=10}

*(c)2017-2026 CHANDLER ZUO ALL RIGHTS PRESERVED*